{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-30T18:17:56.019152Z","iopub.execute_input":"2021-08-30T18:17:56.019536Z","iopub.status.idle":"2021-08-30T18:17:56.037398Z","shell.execute_reply.started":"2021-08-30T18:17:56.019457Z","shell.execute_reply":"2021-08-30T18:17:56.036560Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/30days-folds/train_folds.csv\n/kaggle/input/30daysofmlraw/sample_submission.csv\n/kaggle/input/30daysofmlraw/train.csv\n/kaggle/input/30daysofmlraw/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import optuna\ntrain = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ntest = pd.read_csv(\"../input/30daysofmlraw/test.csv\")\nsample_submission = pd.read_csv(\"../input/30daysofmlraw/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-30T18:17:59.989467Z","iopub.execute_input":"2021-08-30T18:17:59.989809Z","iopub.status.idle":"2021-08-30T18:18:02.586429Z","shell.execute_reply.started":"2021-08-30T18:17:59.989777Z","shell.execute_reply":"2021-08-30T18:18:02.585572Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#target encoding\ndf=train.copy()\ndf_test=test.copy()\nuseful_features=[col for col in df.columns if col not in ('id','kfold','target')]\nobject_cols = [col for col in useful_features if 'cat' in col]\ndf_test = df_test[useful_features]\nfor col in object_cols:\n    temp_df = []\n    temp_test_feat = None\n    \n    for fold in range(5):\n        xtrain=df[df.kfold!=fold].reset_index(drop=True)\n        xvalid=df[df.kfold==fold].reset_index(drop=True)\n        feat=xtrain.groupby(col)['target'].agg(\"mean\")\n        feat=feat.to_dict()\n        xvalid.loc[:,f'tar_enc_{col}']=xvalid[col].map(feat)\n        temp_df.append(xvalid)\n        if temp_test_feat is None:\n            temp_test_feat=df_test[col].map(feat)\n        else:\n            temp_test_feat += df_test[col].map(feat)\n     \n    temp_test_feat /= 5\n    df_test.loc[:, f\"tar_enc_{col}\"] = temp_test_feat\n    df = pd.concat(temp_df)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-30T18:18:08.881692Z","iopub.execute_input":"2021-08-30T18:18:08.882041Z","iopub.status.idle":"2021-08-30T18:18:15.722901Z","shell.execute_reply.started":"2021-08-30T18:18:08.882012Z","shell.execute_reply":"2021-08-30T18:18:15.721999Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#parameters\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\n\n# Model hyperparameters\nxgb_params = {\n'lambda': 67.79737006663706,\n'alpha': 40.12405005448161,\n'colsample_bytree': 0.061613774851329205,\n'subsample': 0.9556736521337416,\n'learning_rate': 0.17024722721525629,\n'n_estimators': 9489,\n'max_depth': 3,\n'booster': 'gbtree',\n'min_child_weight': 155,\n'seed' : 38,\n    #'tree_method':'gpu_hist'\n}\n","metadata":{"execution":{"iopub.status.busy":"2021-08-30T18:18:23.099311Z","iopub.execute_input":"2021-08-30T18:18:23.099649Z","iopub.status.idle":"2021-08-30T18:18:23.105233Z","shell.execute_reply.started":"2021-08-30T18:18:23.099612Z","shell.execute_reply":"2021-08-30T18:18:23.104120Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#hyperparameter optimization\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom xgboost import XGBRegressor\n# Model hyperparameters\ndef run(trial):\n    fold = 4\n    learning_rate = trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True)\n    reg_lambda = trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0)\n    reg_alpha = trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0)\n    subsample = trial.suggest_float(\"subsample\", 0.1, 1.0)\n    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n    max_depth = trial.suggest_int(\"max_depth\", 1, 7)\n\n    xtrain = df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n\n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n\n    ordinal_encoder = OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    model = XGBRegressor(\n        random_state=42,\n        tree_method=\"gpu_hist\",\n        gpu_id=1,\n        predictor=\"gpu_predictor\",\n        learning_rate=learning_rate,\n        reg_lambda=reg_lambda,\n        reg_alpha=reg_alpha,\n        subsample=subsample,\n        colsample_bytree=colsample_bytree,\n        max_depth=max_depth,\n        n_estimators=9849\n    )\n    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n    preds_valid = model.predict(xvalid)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    return rmse","metadata":{"execution":{"iopub.status.busy":"2021-08-30T04:12:20.572981Z","iopub.execute_input":"2021-08-30T04:12:20.573351Z","iopub.status.idle":"2021-08-30T04:12:20.584754Z","shell.execute_reply.started":"2021-08-30T04:12:20.573322Z","shell.execute_reply":"2021-08-30T04:12:20.583649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction=\"minimize\")\nstudy.optimize(run, n_trials=30)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T04:12:28.747661Z","iopub.execute_input":"2021-08-30T04:12:28.748145Z","iopub.status.idle":"2021-08-30T04:21:28.20152Z","shell.execute_reply.started":"2021-08-30T04:12:28.748101Z","shell.execute_reply":"2021-08-30T04:21:28.200593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study.best_params","metadata":{"execution":{"iopub.status.busy":"2021-08-30T04:22:35.149676Z","iopub.execute_input":"2021-08-30T04:22:35.15002Z","iopub.status.idle":"2021-08-30T04:22:35.157075Z","shell.execute_reply.started":"2021-08-30T04:22:35.14997Z","shell.execute_reply":"2021-08-30T04:22:35.156212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params={'learning_rate': 0.024995588074037102,\n 'reg_lambda': 0.02404294288572649,\n 'reg_alpha': 6.366939727261077,\n 'subsample': 0.8852191911768938,\n 'colsample_bytree': 0.16262421334504829,\n 'max_depth': 3}\nxgb_params_hyp={'n_estimators': 7000,\n                **params,\n                'random_state': 0\n               }\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom xgboost import XGBRegressor\n\npreds = 0\nscores = []\nnumerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\nuseful_features=[col for col in df.columns if col not in ('id','kfold','target')]\n\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    scaler = StandardScaler()\n    xtrain[numerical_cols] = scaler.fit_transform(xtrain[numerical_cols])\n    xvalid[numerical_cols] = scaler.transform(xvalid[numerical_cols])\n    xtest[numerical_cols] = scaler.transform(xtest[numerical_cols])\n    #print(xtrain.shape,xvalid.shape,xtest.shape)\n    model = XGBRegressor(**xgb_params_hyp,eval_metric = \"rmse\")\n    model.fit(xtrain, ytrain,early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n    preds_valid = model.predict(xvalid)\n    \n    #Mean of the predictions\n    preds += model.predict(xtest) / 5# Splits\n    \n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-30T04:34:00.971445Z","iopub.execute_input":"2021-08-30T04:34:00.971785Z","iopub.status.idle":"2021-08-30T05:58:04.132044Z","shell.execute_reply.started":"2021-08-30T04:34:00.971754Z","shell.execute_reply":"2021-08-30T05:58:04.131288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BLENDING (USING 4 MODELS)","metadata":{}},{"cell_type":"markdown","source":"# MODEL 1","metadata":{}},{"cell_type":"code","source":"#blending\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom xgboost import XGBRegressor\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\n\nuseful_features=[col for col in df.columns if col not in ('id','kfold','target')]\nobject_cols = [col for col in useful_features if  col.startswith('cat')]\nnumerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\n\n#model_1\nparams={'learning_rate': 0.024995588074037102,\n 'reg_lambda': 0.02404294288572649,\n 'reg_alpha': 6.366939727261077,\n 'subsample': 0.8852191911768938,\n 'colsample_bytree': 0.16262421334504829,\n 'max_depth': 3}\nxgb_params_hyp={'n_estimators': 7000,\n                **params\n               }\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    xtest  = xtest[useful_features]\n    \n    ordinal_encoder = OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    #scaler\n    scaler = StandardScaler()\n    xtrain[numerical_cols] = scaler.fit_transform(xtrain[numerical_cols])\n    xvalid[numerical_cols] = scaler.transform(xvalid[numerical_cols])\n    xtest[numerical_cols] = scaler.transform(xtest[numerical_cols])\n    \n    model = XGBRegressor(\n        random_state=fold,\n#         tree_method='gpu_hist',\n#         gpu_id=0,\n#         predictor=\"gpu_predictor\",\n        **xgb_params_hyp\n        \n    )\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores))\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_1\"]\nfinal_valid_predictions.to_csv(\"train_pred_1.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"id\", \"pred_1\"]\nsample_submission.to_csv(\"test_pred_1.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T18:59:54.938669Z","iopub.execute_input":"2021-08-30T18:59:54.939022Z","iopub.status.idle":"2021-08-30T19:52:05.587692Z","shell.execute_reply.started":"2021-08-30T18:59:54.938991Z","shell.execute_reply":"2021-08-30T19:52:05.586827Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"0 0.7162172508614747\n1 0.7161453514849473\n2 0.7181290054144798\n3 0.7178460933001035\n4 0.7163238041108974\n0.7169323010343805\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:70: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# MODEL 2","metadata":{}},{"cell_type":"code","source":"!pip uninstall -y lightgbm\n!apt-get install -y libboost-all-dev\n!git clone --recursive https://github.com/Microsoft/LightGBM","metadata":{"execution":{"iopub.status.busy":"2021-08-30T18:19:07.330174Z","iopub.execute_input":"2021-08-30T18:19:07.330499Z","iopub.status.idle":"2021-08-30T18:19:36.273101Z","shell.execute_reply.started":"2021-08-30T18:19:07.330466Z","shell.execute_reply":"2021-08-30T18:19:36.272208Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found existing installation: lightgbm 3.2.1.99\nUninstalling lightgbm-3.2.1.99:\n  Successfully uninstalled lightgbm-3.2.1.99\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nlibboost-all-dev is already the newest version (1.65.1.0ubuntu1).\n0 upgraded, 0 newly installed, 0 to remove and 12 not upgraded.\nCloning into 'LightGBM'...\nremote: Enumerating objects: 23316, done.\u001b[K\nremote: Counting objects: 100% (995/995), done.\u001b[K\nremote: Compressing objects: 100% (548/548), done.\u001b[K\nremote: Total 23316 (delta 613), reused 732 (delta 427), pack-reused 22321\u001b[K\nReceiving objects: 100% (23316/23316), 18.00 MiB | 22.82 MiB/s, done.\nResolving deltas: 100% (17012/17012), done.\nSubmodule 'include/boost/compute' (https://github.com/boostorg/compute) registered for path 'external_libs/compute'\nSubmodule 'eigen' (https://gitlab.com/libeigen/eigen.git) registered for path 'external_libs/eigen'\nSubmodule 'external_libs/fast_double_parser' (https://github.com/lemire/fast_double_parser.git) registered for path 'external_libs/fast_double_parser'\nSubmodule 'external_libs/fmt' (https://github.com/fmtlib/fmt.git) registered for path 'external_libs/fmt'\nCloning into '/kaggle/working/LightGBM/external_libs/compute'...\nremote: Enumerating objects: 21731, done.        \nremote: Counting objects: 100% (3/3), done.        \nremote: Compressing objects: 100% (3/3), done.        \nremote: Total 21731 (delta 0), reused 1 (delta 0), pack-reused 21728        \nReceiving objects: 100% (21731/21731), 8.51 MiB | 15.51 MiB/s, done.\nResolving deltas: 100% (17566/17566), done.\nCloning into '/kaggle/working/LightGBM/external_libs/eigen'...\nremote: Enumerating objects: 111163, done.        \nremote: Counting objects: 100% (787/787), done.        \nremote: Compressing objects: 100% (467/467), done.        \nremote: Total 111163 (delta 427), reused 637 (delta 311), pack-reused 110376        \nReceiving objects: 100% (111163/111163), 102.35 MiB | 21.54 MiB/s, done.\nResolving deltas: 100% (91220/91220), done.\nCloning into '/kaggle/working/LightGBM/external_libs/fast_double_parser'...\nremote: Enumerating objects: 689, done.        \nremote: Counting objects: 100% (189/189), done.        \nremote: Compressing objects: 100% (121/121), done.        \nremote: Total 689 (delta 93), reused 99 (delta 41), pack-reused 500        \nReceiving objects: 100% (689/689), 802.19 KiB | 3.08 MiB/s, done.\nResolving deltas: 100% (347/347), done.\nCloning into '/kaggle/working/LightGBM/external_libs/fmt'...\nremote: Enumerating objects: 27156, done.        \nremote: Counting objects: 100% (864/864), done.        \nremote: Compressing objects: 100% (343/343), done.        \nremote: Total 27156 (delta 520), reused 706 (delta 423), pack-reused 26292        \nReceiving objects: 100% (27156/27156), 13.44 MiB | 19.17 MiB/s, done.\nResolving deltas: 100% (18321/18321), done.\nSubmodule path 'external_libs/compute': checked out '36c89134d4013b2e5e45bc55656a18bd6141995a'\nSubmodule path 'external_libs/eigen': checked out '8ba1b0f41a7950dc3e1d4ed75859e36c73311235'\nSubmodule path 'external_libs/fast_double_parser': checked out 'ace60646c02dc54c57f19d644e49a61e7e7758ec'\nSubmodule 'benchmark/dependencies/abseil-cpp' (https://github.com/abseil/abseil-cpp.git) registered for path 'external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp'\nSubmodule 'benchmark/dependencies/double-conversion' (https://github.com/google/double-conversion.git) registered for path 'external_libs/fast_double_parser/benchmarks/dependencies/double-conversion'\nCloning into '/kaggle/working/LightGBM/external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp'...\nremote: Enumerating objects: 15092, done.        \nremote: Counting objects: 100% (1099/1099), done.        \nremote: Compressing objects: 100% (567/567), done.        \nremote: Total 15092 (delta 717), reused 847 (delta 531), pack-reused 13993        \nReceiving objects: 100% (15092/15092), 10.27 MiB | 17.36 MiB/s, done.\nResolving deltas: 100% (11395/11395), done.\nCloning into '/kaggle/working/LightGBM/external_libs/fast_double_parser/benchmarks/dependencies/double-conversion'...\nremote: Enumerating objects: 1235, done.        \nremote: Counting objects: 100% (79/79), done.        \nremote: Compressing objects: 100% (60/60), done.        \nremote: Total 1235 (delta 45), reused 39 (delta 19), pack-reused 1156        \nReceiving objects: 100% (1235/1235), 7.09 MiB | 13.11 MiB/s, done.\nResolving deltas: 100% (817/817), done.\nSubmodule path 'external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp': checked out 'd936052d32a5b7ca08b0199a6724724aea432309'\nSubmodule path 'external_libs/fast_double_parser/benchmarks/dependencies/double-conversion': checked out 'f4cb2384efa55dee0e6652f8674b05763441ab09'\nSubmodule path 'external_libs/fmt': checked out 'cc09f1a6798c085c325569ef466bcdcffdc266d4'\n","output_type":"stream"}]},{"cell_type":"code","source":"%%bash\ncd LightGBM\nrm -r build\nmkdir build\ncd build\ncmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..\nmake -j$(nproc)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T18:20:19.195410Z","iopub.execute_input":"2021-08-30T18:20:19.195778Z","iopub.status.idle":"2021-08-30T18:24:49.643652Z","shell.execute_reply.started":"2021-08-30T18:20:19.195719Z","shell.execute_reply":"2021-08-30T18:24:49.642803Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"-- The C compiler identification is GNU 7.5.0\n-- The CXX compiler identification is GNU 7.5.0\n-- Check for working C compiler: /usr/bin/cc\n-- Check for working C compiler: /usr/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /usr/bin/c++\n-- Check for working CXX compiler: /usr/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n-- Found OpenMP: TRUE (found version \"4.5\")  \n-- Looking for CL_VERSION_2_2\n-- Looking for CL_VERSION_2_2 - not found\n-- Looking for CL_VERSION_2_1\n-- Looking for CL_VERSION_2_1 - not found\n-- Looking for CL_VERSION_2_0\n-- Looking for CL_VERSION_2_0 - not found\n-- Looking for CL_VERSION_1_2\n-- Looking for CL_VERSION_1_2 - found\n-- Found OpenCL: /usr/local/cuda/lib64/libOpenCL.so (found version \"1.2\") \n-- OpenCL include directory: /usr/local/cuda/include\n-- Boost 1.56.0 found.\n-- Found Boost components:\n   filesystem;system\n-- Performing Test MM_PREFETCH\n-- Performing Test MM_PREFETCH - Success\n-- Using _mm_prefetch\n-- Performing Test MM_MALLOC\n-- Performing Test MM_MALLOC - Success\n-- Using _mm_malloc\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /kaggle/working/LightGBM/build\nScanning dependencies of target lightgbm\nScanning dependencies of target _lightgbm\n[  2%] Building CXX object CMakeFiles/lightgbm.dir/src/main.cpp.o\n[  2%] Building CXX object CMakeFiles/_lightgbm.dir/src/boosting/boosting.cpp.o\n[  4%] Building CXX object CMakeFiles/lightgbm.dir/src/application/application.cpp.o\n[  5%] Building CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt.cpp.o\n[  7%] Building CXX object CMakeFiles/lightgbm.dir/src/boosting/boosting.cpp.o\n[  8%] Building CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\n[ 10%] Building CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt.cpp.o\n[ 11%] Building CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\n[ 13%] Building CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\n[ 14%] Building CXX object CMakeFiles/_lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\n[ 15%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/bin.cpp.o\n[ 17%] Building CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\n[ 18%] Building CXX object CMakeFiles/lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\n[ 20%] Building CXX object CMakeFiles/lightgbm.dir/src/io/bin.cpp.o\n[ 21%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/config.cpp.o\n[ 23%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/config_auto.cpp.o\n[ 24%] Building CXX object CMakeFiles/lightgbm.dir/src/io/config.cpp.o\n[ 26%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/dataset.cpp.o\n[ 27%] Building CXX object CMakeFiles/lightgbm.dir/src/io/config_auto.cpp.o\n[ 28%] Building CXX object CMakeFiles/lightgbm.dir/src/io/dataset.cpp.o\n[ 30%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/dataset_loader.cpp.o\n[ 31%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/file_io.cpp.o\n[ 33%] Building CXX object CMakeFiles/lightgbm.dir/src/io/dataset_loader.cpp.o\n[ 34%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/json11.cpp.o\n[ 36%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/metadata.cpp.o\n[ 37%] Building CXX object CMakeFiles/lightgbm.dir/src/io/file_io.cpp.o\n[ 39%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/parser.cpp.o\n[ 40%] Building CXX object CMakeFiles/lightgbm.dir/src/io/json11.cpp.o\n[ 42%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/train_share_states.cpp.o\n[ 43%] Building CXX object CMakeFiles/lightgbm.dir/src/io/metadata.cpp.o\n[ 44%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/tree.cpp.o\n[ 46%] Building CXX object CMakeFiles/lightgbm.dir/src/io/parser.cpp.o\n[ 47%] Building CXX object CMakeFiles/lightgbm.dir/src/io/train_share_states.cpp.o\n[ 49%] Building CXX object CMakeFiles/lightgbm.dir/src/io/tree.cpp.o\n[ 50%] Building CXX object CMakeFiles/_lightgbm.dir/src/metric/dcg_calculator.cpp.o\n[ 52%] Building CXX object CMakeFiles/_lightgbm.dir/src/metric/metric.cpp.o\n[ 53%] Building CXX object CMakeFiles/lightgbm.dir/src/metric/dcg_calculator.cpp.o\n[ 55%] Building CXX object CMakeFiles/lightgbm.dir/src/metric/metric.cpp.o\n[ 56%] Building CXX object CMakeFiles/_lightgbm.dir/src/objective/objective_function.cpp.o\n[ 57%] Building CXX object CMakeFiles/lightgbm.dir/src/objective/objective_function.cpp.o\n[ 59%] Building CXX object CMakeFiles/_lightgbm.dir/src/network/ifaddrs_patch.cpp.o\n[ 60%] Building CXX object CMakeFiles/_lightgbm.dir/src/network/linker_topo.cpp.o\n[ 62%] Building CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_mpi.cpp.o\n[ 63%] Building CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_socket.cpp.o\n[ 65%] Building CXX object CMakeFiles/_lightgbm.dir/src/network/network.cpp.o\n[ 66%] Building CXX object CMakeFiles/lightgbm.dir/src/network/ifaddrs_patch.cpp.o\n[ 68%] Building CXX object CMakeFiles/lightgbm.dir/src/network/linker_topo.cpp.o\n[ 69%] Building CXX object CMakeFiles/_lightgbm.dir/src/treelearner/cuda_tree_learner.cpp.o\n[ 71%] Building CXX object CMakeFiles/_lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\n[ 72%] Building CXX object CMakeFiles/lightgbm.dir/src/network/linkers_mpi.cpp.o\n[ 73%] Building CXX object CMakeFiles/lightgbm.dir/src/network/linkers_socket.cpp.o\n[ 75%] Building CXX object CMakeFiles/lightgbm.dir/src/network/network.cpp.o\n[ 76%] Building CXX object CMakeFiles/lightgbm.dir/src/treelearner/cuda_tree_learner.cpp.o\n[ 78%] Building CXX object CMakeFiles/lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\n[ 79%] Building CXX object CMakeFiles/_lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\n[ 81%] Building CXX object CMakeFiles/lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\n[ 82%] Building CXX object CMakeFiles/_lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\n[ 84%] Building CXX object CMakeFiles/lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\n[ 85%] Building CXX object CMakeFiles/_lightgbm.dir/src/treelearner/linear_tree_learner.cpp.o\n[ 86%] Building CXX object CMakeFiles/lightgbm.dir/src/treelearner/linear_tree_learner.cpp.o\n[ 88%] Building CXX object CMakeFiles/_lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\n[ 89%] Building CXX object CMakeFiles/lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\n[ 91%] Building CXX object CMakeFiles/_lightgbm.dir/src/treelearner/tree_learner.cpp.o\n[ 92%] Building CXX object CMakeFiles/lightgbm.dir/src/treelearner/tree_learner.cpp.o\n[ 94%] Building CXX object CMakeFiles/_lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\n[ 95%] Building CXX object CMakeFiles/lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\n[ 97%] Building CXX object CMakeFiles/_lightgbm.dir/src/c_api.cpp.o\n[ 98%] Linking CXX executable ../lightgbm\n[ 98%] Built target lightgbm\n[100%] Linking CXX shared library ../lib_lightgbm.so\n[100%] Built target _lightgbm\n","output_type":"stream"},{"name":"stderr","text":"rm: cannot remove 'build': No such file or directory\ncmake: /opt/conda/lib/libcurl.so.4: no version information available (required by cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\nIn file included from /opt/conda/include/boost/property_tree/json_parser/detail/parser.hpp:7:0,\n                 from /opt/conda/include/boost/property_tree/json_parser/detail/read.hpp:13,\n                 from /opt/conda/include/boost/property_tree/json_parser.hpp:16,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/detail/parameter_cache.hpp:31,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/algorithm/detail/copy_on_device.hpp:23,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/algorithm/copy.hpp:26,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/container/vector.hpp:32,\n                 from /kaggle/working/LightGBM/src/treelearner/gpu_tree_learner.h:34,\n                 from /kaggle/working/LightGBM/src/treelearner/parallel_tree_learner.h:16,\n                 from /kaggle/working/LightGBM/src/treelearner/data_parallel_tree_learner.cpp:9:\n/opt/conda/include/boost/bind.hpp:41:1: note: #pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n )\n ^\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\nIn file included from /opt/conda/include/boost/property_tree/json_parser/detail/parser.hpp:7:0,\n                 from /opt/conda/include/boost/property_tree/json_parser/detail/read.hpp:13,\n                 from /opt/conda/include/boost/property_tree/json_parser.hpp:16,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/detail/parameter_cache.hpp:31,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/algorithm/detail/copy_on_device.hpp:23,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/algorithm/copy.hpp:26,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/container/vector.hpp:32,\n                 from /kaggle/working/LightGBM/src/treelearner/gpu_tree_learner.h:34,\n                 from /kaggle/working/LightGBM/src/treelearner/parallel_tree_learner.h:16,\n                 from /kaggle/working/LightGBM/src/treelearner/data_parallel_tree_learner.cpp:9:\n/opt/conda/include/boost/bind.hpp:41:1: note: #pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n )\n ^\nIn file included from /opt/conda/include/boost/property_tree/json_parser/detail/parser.hpp:7:0,\n                 from /opt/conda/include/boost/property_tree/json_parser/detail/read.hpp:13,\n                 from /opt/conda/include/boost/property_tree/json_parser.hpp:16,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/detail/parameter_cache.hpp:31,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/algorithm/detail/copy_on_device.hpp:23,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/algorithm/copy.hpp:26,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/container/vector.hpp:32,\n                 from /kaggle/working/LightGBM/src/treelearner/gpu_tree_learner.h:34,\n                 from /kaggle/working/LightGBM/src/treelearner/parallel_tree_learner.h:16,\n                 from /kaggle/working/LightGBM/src/treelearner/feature_parallel_tree_learner.cpp:8:\n/opt/conda/include/boost/bind.hpp:41:1: note: #pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n )\n ^\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\nIn file included from /opt/conda/include/boost/property_tree/json_parser/detail/parser.hpp:7:0,\n                 from /opt/conda/include/boost/property_tree/json_parser/detail/read.hpp:13,\n                 from /opt/conda/include/boost/property_tree/json_parser.hpp:16,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/detail/parameter_cache.hpp:31,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/algorithm/detail/copy_on_device.hpp:23,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/algorithm/copy.hpp:26,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/container/vector.hpp:32,\n                 from /kaggle/working/LightGBM/src/treelearner/gpu_tree_learner.h:34,\n                 from /kaggle/working/LightGBM/src/treelearner/parallel_tree_learner.h:16,\n                 from /kaggle/working/LightGBM/src/treelearner/feature_parallel_tree_learner.cpp:8:\n/opt/conda/include/boost/bind.hpp:41:1: note: #pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n )\n ^\nIn file included from /opt/conda/include/boost/property_tree/json_parser/detail/parser.hpp:7:0,\n                 from /opt/conda/include/boost/property_tree/json_parser/detail/read.hpp:13,\n                 from /opt/conda/include/boost/property_tree/json_parser.hpp:16,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/detail/parameter_cache.hpp:31,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/algorithm/detail/copy_on_device.hpp:23,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/algorithm/copy.hpp:26,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/container/vector.hpp:32,\n                 from /kaggle/working/LightGBM/src/treelearner/gpu_tree_learner.h:34,\n                 from /kaggle/working/LightGBM/src/treelearner/gpu_tree_learner.cpp:7:\n/opt/conda/include/boost/bind.hpp:41:1: note: #pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n )\n ^\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\nIn file included from /opt/conda/include/boost/property_tree/json_parser/detail/parser.hpp:7:0,\n                 from /opt/conda/include/boost/property_tree/json_parser/detail/read.hpp:13,\n                 from /opt/conda/include/boost/property_tree/json_parser.hpp:16,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/detail/parameter_cache.hpp:31,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/algorithm/detail/copy_on_device.hpp:23,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/algorithm/copy.hpp:26,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/container/vector.hpp:32,\n                 from /kaggle/working/LightGBM/src/treelearner/gpu_tree_learner.h:34,\n                 from /kaggle/working/LightGBM/src/treelearner/gpu_tree_learner.cpp:7:\n/opt/conda/include/boost/bind.hpp:41:1: note: #pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n )\n ^\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\nIn file included from /opt/conda/include/boost/property_tree/json_parser/detail/parser.hpp:7:0,\n                 from /opt/conda/include/boost/property_tree/json_parser/detail/read.hpp:13,\n                 from /opt/conda/include/boost/property_tree/json_parser.hpp:16,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/detail/parameter_cache.hpp:31,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/algorithm/detail/copy_on_device.hpp:23,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/algorithm/copy.hpp:26,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/container/vector.hpp:32,\n                 from /kaggle/working/LightGBM/src/treelearner/gpu_tree_learner.h:34,\n                 from /kaggle/working/LightGBM/src/treelearner/tree_learner.cpp:8:\n/opt/conda/include/boost/bind.hpp:41:1: note: #pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n )\n ^\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\nIn file included from /opt/conda/include/boost/property_tree/json_parser/detail/parser.hpp:7:0,\n                 from /opt/conda/include/boost/property_tree/json_parser/detail/read.hpp:13,\n                 from /opt/conda/include/boost/property_tree/json_parser.hpp:16,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/detail/parameter_cache.hpp:31,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/algorithm/detail/copy_on_device.hpp:23,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/algorithm/copy.hpp:26,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/container/vector.hpp:32,\n                 from /kaggle/working/LightGBM/src/treelearner/gpu_tree_learner.h:34,\n                 from /kaggle/working/LightGBM/src/treelearner/tree_learner.cpp:8:\n/opt/conda/include/boost/bind.hpp:41:1: note: #pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n )\n ^\nIn file included from /opt/conda/include/boost/property_tree/json_parser/detail/parser.hpp:7:0,\n                 from /opt/conda/include/boost/property_tree/json_parser/detail/read.hpp:13,\n                 from /opt/conda/include/boost/property_tree/json_parser.hpp:16,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/detail/parameter_cache.hpp:31,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/algorithm/detail/copy_on_device.hpp:23,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/algorithm/copy.hpp:26,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/container/vector.hpp:32,\n                 from /kaggle/working/LightGBM/src/treelearner/gpu_tree_learner.h:34,\n                 from /kaggle/working/LightGBM/src/treelearner/parallel_tree_learner.h:16,\n                 from /kaggle/working/LightGBM/src/treelearner/voting_parallel_tree_learner.cpp:11:\n/opt/conda/include/boost/bind.hpp:41:1: note: #pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n )\n ^\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\nIn file included from /opt/conda/include/boost/property_tree/json_parser/detail/parser.hpp:7:0,\n                 from /opt/conda/include/boost/property_tree/json_parser/detail/read.hpp:13,\n                 from /opt/conda/include/boost/property_tree/json_parser.hpp:16,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/detail/parameter_cache.hpp:31,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/algorithm/detail/copy_on_device.hpp:23,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/algorithm/copy.hpp:26,\n                 from /kaggle/working/LightGBM/external_libs/compute/include/boost/compute/container/vector.hpp:32,\n                 from /kaggle/working/LightGBM/src/treelearner/gpu_tree_learner.h:34,\n                 from /kaggle/working/LightGBM/src/treelearner/parallel_tree_learner.h:16,\n                 from /kaggle/working/LightGBM/src/treelearner/voting_parallel_tree_learner.cpp:11:\n/opt/conda/include/boost/bind.hpp:41:1: note: #pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n )\n ^\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n","output_type":"stream"}]},{"cell_type":"code","source":"!cd LightGBM/python-package/;python setup.py install --precompile","metadata":{"execution":{"iopub.status.busy":"2021-08-30T18:25:24.670331Z","iopub.execute_input":"2021-08-30T18:25:24.670717Z","iopub.status.idle":"2021-08-30T18:25:26.032641Z","shell.execute_reply.started":"2021-08-30T18:25:24.670678Z","shell.execute_reply":"2021-08-30T18:25:26.031752Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"running install\nrunning build\nrunning build_py\ncreating build\ncreating build/lib\ncreating build/lib/lightgbm\ncopying lightgbm/callback.py -> build/lib/lightgbm\ncopying lightgbm/compat.py -> build/lib/lightgbm\ncopying lightgbm/sklearn.py -> build/lib/lightgbm\ncopying lightgbm/libpath.py -> build/lib/lightgbm\ncopying lightgbm/basic.py -> build/lib/lightgbm\ncopying lightgbm/dask.py -> build/lib/lightgbm\ncopying lightgbm/plotting.py -> build/lib/lightgbm\ncopying lightgbm/engine.py -> build/lib/lightgbm\ncopying lightgbm/__init__.py -> build/lib/lightgbm\nrunning egg_info\ncreating lightgbm.egg-info\nwriting lightgbm.egg-info/PKG-INFO\nwriting dependency_links to lightgbm.egg-info/dependency_links.txt\nwriting requirements to lightgbm.egg-info/requires.txt\nwriting top-level names to lightgbm.egg-info/top_level.txt\nwriting manifest file 'lightgbm.egg-info/SOURCES.txt'\nreading manifest template 'MANIFEST.in'\nno previously-included directories found matching 'build'\nwarning: no files found matching 'LICENSE'\nwarning: no files found matching '*.txt'\nwarning: no files found matching '*.so' under directory 'lightgbm'\nwarning: no files found matching 'compile/CMakeLists.txt'\nwarning: no files found matching 'compile/cmake/IntegratedOpenCL.cmake'\nwarning: no files found matching '*.so' under directory 'compile'\nwarning: no files found matching '*.dll' under directory 'compile/Release'\nwarning: no files found matching 'compile/external_libs/compute/CMakeLists.txt'\nwarning: no files found matching '*' under directory 'compile/external_libs/compute/cmake'\nwarning: no files found matching '*' under directory 'compile/external_libs/compute/include'\nwarning: no files found matching '*' under directory 'compile/external_libs/compute/meta'\nwarning: no files found matching 'compile/external_libs/eigen/CMakeLists.txt'\nwarning: no files found matching 'compile/external_libs/eigen/Eigen/Cholesky'\nwarning: no files found matching 'compile/external_libs/eigen/Eigen/Core'\nwarning: no files found matching 'compile/external_libs/eigen/Eigen/Dense'\nwarning: no files found matching 'compile/external_libs/eigen/Eigen/Eigenvalues'\nwarning: no files found matching 'compile/external_libs/eigen/Eigen/Geometry'\nwarning: no files found matching 'compile/external_libs/eigen/Eigen/Householder'\nwarning: no files found matching 'compile/external_libs/eigen/Eigen/Jacobi'\nwarning: no files found matching 'compile/external_libs/eigen/Eigen/LU'\nwarning: no files found matching 'compile/external_libs/eigen/Eigen/QR'\nwarning: no files found matching 'compile/external_libs/eigen/Eigen/SVD'\nwarning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Cholesky'\nwarning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Core'\nwarning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Eigenvalues'\nwarning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Geometry'\nwarning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Householder'\nwarning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Jacobi'\nwarning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/LU'\nwarning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/misc'\nwarning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/plugins'\nwarning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/QR'\nwarning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/SVD'\nwarning: no files found matching 'compile/external_libs/fast_double_parser/CMakeLists.txt'\nwarning: no files found matching 'compile/external_libs/fast_double_parser/LICENSE'\nwarning: no files found matching 'compile/external_libs/fast_double_parser/LICENSE.BSL'\nwarning: no files found matching '*' under directory 'compile/external_libs/fast_double_parser/include'\nwarning: no files found matching 'compile/external_libs/fmt/CMakeLists.txt'\nwarning: no files found matching 'compile/external_libs/fmt/LICENSE.rst'\nwarning: no files found matching '*' under directory 'compile/external_libs/fmt/include'\nwarning: no files found matching '*' under directory 'compile/include'\nwarning: no files found matching '*' under directory 'compile/src'\nwarning: no files found matching 'LightGBM.sln' under directory 'compile/windows'\nwarning: no files found matching 'LightGBM.vcxproj' under directory 'compile/windows'\nwarning: no files found matching '*.dll' under directory 'compile/windows/x64/DLL'\nwarning: no previously-included files matching '*.py[co]' found anywhere in distribution\nwarning: no previously-included files found matching 'compile/external_libs/compute/.git'\nwriting manifest file 'lightgbm.egg-info/SOURCES.txt'\ncopying lightgbm/VERSION.txt -> build/lib/lightgbm\nrunning install_lib\ncreating /opt/conda/lib/python3.7/site-packages/lightgbm\ncopying build/lib/lightgbm/callback.py -> /opt/conda/lib/python3.7/site-packages/lightgbm\ncopying build/lib/lightgbm/compat.py -> /opt/conda/lib/python3.7/site-packages/lightgbm\ncopying build/lib/lightgbm/VERSION.txt -> /opt/conda/lib/python3.7/site-packages/lightgbm\ncopying build/lib/lightgbm/sklearn.py -> /opt/conda/lib/python3.7/site-packages/lightgbm\ncopying build/lib/lightgbm/libpath.py -> /opt/conda/lib/python3.7/site-packages/lightgbm\ncopying build/lib/lightgbm/basic.py -> /opt/conda/lib/python3.7/site-packages/lightgbm\ncopying build/lib/lightgbm/dask.py -> /opt/conda/lib/python3.7/site-packages/lightgbm\ncopying build/lib/lightgbm/plotting.py -> /opt/conda/lib/python3.7/site-packages/lightgbm\ncopying build/lib/lightgbm/engine.py -> /opt/conda/lib/python3.7/site-packages/lightgbm\ncopying build/lib/lightgbm/__init__.py -> /opt/conda/lib/python3.7/site-packages/lightgbm\ncopying /kaggle/working/LightGBM/lib_lightgbm.so -> /opt/conda/lib/python3.7/site-packages/lightgbm\nbyte-compiling /opt/conda/lib/python3.7/site-packages/lightgbm/callback.py to callback.cpython-37.pyc\nbyte-compiling /opt/conda/lib/python3.7/site-packages/lightgbm/compat.py to compat.cpython-37.pyc\nbyte-compiling /opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py to sklearn.cpython-37.pyc\nbyte-compiling /opt/conda/lib/python3.7/site-packages/lightgbm/libpath.py to libpath.cpython-37.pyc\nbyte-compiling /opt/conda/lib/python3.7/site-packages/lightgbm/basic.py to basic.cpython-37.pyc\nbyte-compiling /opt/conda/lib/python3.7/site-packages/lightgbm/dask.py to dask.cpython-37.pyc\nbyte-compiling /opt/conda/lib/python3.7/site-packages/lightgbm/plotting.py to plotting.cpython-37.pyc\nbyte-compiling /opt/conda/lib/python3.7/site-packages/lightgbm/engine.py to engine.cpython-37.pyc\nbyte-compiling /opt/conda/lib/python3.7/site-packages/lightgbm/__init__.py to __init__.cpython-37.pyc\nrunning install_egg_info\nCopying lightgbm.egg-info to /opt/conda/lib/python3.7/site-packages/lightgbm-3.2.1.99-py3.7.egg-info\nrunning install_scripts\n","output_type":"stream"}]},{"cell_type":"code","source":"!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n!rm -r LightGBM","metadata":{"execution":{"iopub.status.busy":"2021-08-30T18:25:33.162558Z","iopub.execute_input":"2021-08-30T18:25:33.163002Z","iopub.status.idle":"2021-08-30T18:25:34.631230Z","shell.execute_reply.started":"2021-08-30T18:25:33.162955Z","shell.execute_reply":"2021-08-30T18:25:34.630142Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T17:48:19.285676Z","iopub.execute_input":"2021-08-30T17:48:19.286077Z","iopub.status.idle":"2021-08-30T17:48:19.319469Z","shell.execute_reply.started":"2021-08-30T17:48:19.286045Z","shell.execute_reply":"2021-08-30T17:48:19.318339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.preprocessing import OrdinalEncoder\nfinal_valid_predictions = {}\nfinal_test_predictions=[]\nscores = []\n\ndf = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30daysofmlraw/test.csv\")\nsample_submission = pd.read_csv(\"../input/30daysofmlraw/sample_submission.csv\")\n\n\nuseful_features=[col for col in df.columns if col not in ('id','kfold','target')]\nobject_cols = [col for col in useful_features if  col.startswith('cat')]\nnumerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\n\n\n\nimport lightgbm as lgb\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    xtest  = xtest[useful_features]\n    \n    ordinal_encoder = OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    param = {\n        \"objective\": \"regression\",\n        \"metric\": \"rmse\",\n        \"verbosity\": -1,\n        \"boosting_type\": \"gbdt\",\n        \"n_estimators\": 10000,\n        \"early_stopping_round\": 300,\n        \"device\": \"gpu\",\n        \"gpu_platform_id\": 0,\n        \"gpu_device_id\": 0,\n    }\n    \n    param2 = {\n        'lambda_l1': 0.00472279780583036, \n        'lambda_l2': 2.9095205689488508e-05, \n        'num_leaves': 158, \n        'feature_fraction': 0.7386878356648194, \n        'bagging_fraction': 0.8459744550725283, \n        'bagging_freq': 2, \n        'max_depth': 2, \n        'max_bin': 249, \n        'learning_rate': 0.044738463593017294,\n        'min_child_samples': 13\n    }\n    param.update(param2)\n#     param = {\n#     \"random_state\": 0,\n#     \"metric\": \"rmse\",\n#     \"n_jobs\": 6,\n#     \"early_stopping_round\": 200,\n#     \"reg_alpha\": 9.03513073170552,\n#     \"reg_lambda\": 0.024555737897445917,\n#     \"colsample_bytree\": 0.2185112060137363,\n#     \"learning_rate\": 0.003049106861273527,\n#     \"max_depth\": 65,\n#     \"num_leaves\": 51,\n#     \"min_child_samples\": 177,\n#     \"n_estimators\": 8000,\n#     \"cat_smooth\": 93.60968300634175,\n#     \"max_bin\": 537,\n#     \"min_data_per_group\": 117,\n#     \"bagging_freq\": 1,\n#     \"bagging_fraction\": 0.6709049555262285,\n#     \"cat_l2\": 7.5586732660804445,\n#     \"verbose\": -1}\n    lgb_train = lgb.Dataset(xtrain, ytrain)\n    lgb_valid = lgb.Dataset(xvalid, yvalid, reference=lgb_train)\n\n    model = lgb.train(param, lgb_train, valid_sets=[lgb_valid], verbose_eval=1000)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n    \nprint(np.mean(scores), np.std(scores))\nprint(np.mean(scores), np.std(scores))\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_2\"]\nfinal_valid_predictions.to_csv(\"train_pred_2.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"id\", \"pred_2\"]\nsample_submission.to_csv(\"test_pred_2.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T18:30:08.789181Z","iopub.execute_input":"2021-08-30T18:30:08.789525Z","iopub.status.idle":"2021-08-30T18:47:23.475253Z","shell.execute_reply.started":"2021-08-30T18:30:08.789493Z","shell.execute_reply":"2021-08-30T18:47:23.474361Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:182: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","output_type":"stream"},{"name":"stdout","text":"Training until validation scores don't improve for 300 rounds\n[1000]\tvalid_0's rmse: 0.725479\n[2000]\tvalid_0's rmse: 0.72169\n[3000]\tvalid_0's rmse: 0.719718\n[4000]\tvalid_0's rmse: 0.718642\n[5000]\tvalid_0's rmse: 0.718104\n[6000]\tvalid_0's rmse: 0.717781\n[7000]\tvalid_0's rmse: 0.717624\n[8000]\tvalid_0's rmse: 0.717495\nEarly stopping, best iteration is:\n[8326]\tvalid_0's rmse: 0.717471\n0 0.7174711663323653\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:182: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","output_type":"stream"},{"name":"stdout","text":"Training until validation scores don't improve for 300 rounds\n[1000]\tvalid_0's rmse: 0.725113\n[2000]\tvalid_0's rmse: 0.721468\n[3000]\tvalid_0's rmse: 0.719609\n[4000]\tvalid_0's rmse: 0.718685\n[5000]\tvalid_0's rmse: 0.718256\n[6000]\tvalid_0's rmse: 0.718053\nEarly stopping, best iteration is:\n[6252]\tvalid_0's rmse: 0.71799\n1 0.717990209419654\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:182: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","output_type":"stream"},{"name":"stdout","text":"Training until validation scores don't improve for 300 rounds\n[1000]\tvalid_0's rmse: 0.727329\n[2000]\tvalid_0's rmse: 0.723491\n[3000]\tvalid_0's rmse: 0.721569\n[4000]\tvalid_0's rmse: 0.720583\n[5000]\tvalid_0's rmse: 0.720018\n[6000]\tvalid_0's rmse: 0.719776\n[7000]\tvalid_0's rmse: 0.719641\nEarly stopping, best iteration is:\n[7028]\tvalid_0's rmse: 0.719636\n2 0.7196357506965607\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:182: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","output_type":"stream"},{"name":"stdout","text":"Training until validation scores don't improve for 300 rounds\n[1000]\tvalid_0's rmse: 0.726758\n[2000]\tvalid_0's rmse: 0.723115\n[3000]\tvalid_0's rmse: 0.721407\n[4000]\tvalid_0's rmse: 0.720507\n[5000]\tvalid_0's rmse: 0.720028\n[6000]\tvalid_0's rmse: 0.719738\n[7000]\tvalid_0's rmse: 0.719675\nEarly stopping, best iteration is:\n[7081]\tvalid_0's rmse: 0.719663\n3 0.7196632415072806\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:182: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","output_type":"stream"},{"name":"stdout","text":"Training until validation scores don't improve for 300 rounds\n[1000]\tvalid_0's rmse: 0.726165\n[2000]\tvalid_0's rmse: 0.722073\n[3000]\tvalid_0's rmse: 0.720065\n[4000]\tvalid_0's rmse: 0.719127\n[5000]\tvalid_0's rmse: 0.718603\n[6000]\tvalid_0's rmse: 0.718323\n[7000]\tvalid_0's rmse: 0.718168\nEarly stopping, best iteration is:\n[7262]\tvalid_0's rmse: 0.71813\n4 0.718129515675863\n0.7185779767263447 0.0009020313060687815\n0.7185779767263447 0.0009020313060687815\n","output_type":"stream"}]},{"cell_type":"code","source":"final_predictions = []\nscores = []\n\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_2\"]\nfinal_valid_predictions.to_csv(\"train_pred_2.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_predictions), axis=1)\nsample_submission.columns = [\"id\", \"pred_2\"]\nsample_submission.to_csv(\"test_pred_2.csv\", index=False)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODEL 3","metadata":{}},{"cell_type":"code","source":"#model_3 #training model only with continuous features\n#only cat features\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nmodel_3_features = [col for col in useful_features if col.startswith(\"cont\")]\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\n\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[model_3_features]\n    xvalid = xvalid[model_3_features]\n    xtest  = xtest[model_3_features]\n    #numerical_cols and model_3_features col are exactly same\n    \n    \n    \n    model = XGBRegressor(\n        random_state=fold,\n        tree_method='gpu_hist',\n        gpu_id=0,\n        predictor=\"gpu_predictor\",\n        **xgb_params_hyp\n        \n    )\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_3\"]\nfinal_valid_predictions.to_csv(\"train_pred_3.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"id\", \"pred_3\"]\nsample_submission.to_csv(\"test_pred_3.csv\", index=False)\n\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:36:27.339685Z","iopub.execute_input":"2021-08-30T13:36:27.340085Z","iopub.status.idle":"2021-08-30T13:36:29.271928Z","shell.execute_reply.started":"2021-08-30T13:36:27.340052Z","shell.execute_reply":"2021-08-30T13:36:29.269296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODEL 4","metadata":{}},{"cell_type":"code","source":"#model_4 only numerical cols\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nmodel_4_features = [col for col in useful_features if col.startswith('cat')]\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\n\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    xtest  = xtest[model_4_features]\n    xtrain = xtrain[model_4_features]\n    xvalid = xvalid[model_4_features]\n    #object_cols and model_3_features col are exactly same\n    ordinal_encoder = OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    model = XGBRegressor(\n        random_state=fold,\n#         tree_method='gpu_hist',\n#         gpu_id=0,\n#         predictor=\"gpu_predictor\",\n        **xgb_params_hyp\n        \n    )\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_4\"]\nfinal_valid_predictions.to_csv(\"train_pred_4.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"id\", \"pred_4\"]\nsample_submission.to_csv(\"test_pred_4.csv\", index=False)\n\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:14:59.611925Z","iopub.execute_input":"2021-08-30T13:14:59.612291Z","iopub.status.idle":"2021-08-30T13:15:33.268505Z","shell.execute_reply.started":"2021-08-30T13:14:59.612238Z","shell.execute_reply":"2021-08-30T13:15:33.265928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# STACKING ALL OF THEM INTO MAIN TABLE","metadata":{}},{"cell_type":"code","source":"#stacking all the models validations prediction side by side to form a new table\ndf = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30daysofmlraw/test.csv\")\nsample_submission = pd.read_csv(\"../input/30daysofmlraw/sample_submission.csv\")\n\n\ndf1 = pd.read_csv(\"train_pred_1.csv\")\ndf2 = pd.read_csv(\"train_pred_2.csv\")\n# df3 = pd.read_csv(\"train_pred_3.csv\")\n# df4 = pd.read_csv(\"train_pred_4.csv\")\n\ndf_test1 = pd.read_csv(\"test_pred_1.csv\")\ndf_test2 = pd.read_csv(\"test_pred_2.csv\")\n# df_test3 = pd.read_csv(\"test_pred_3.csv\")\n# df_test4 = pd.read_csv(\"test_pred_4.csv\")\n\ndf = df.merge(df1, on=\"id\", how=\"left\")\ndf = df.merge(df2, on=\"id\", how=\"left\")\n# df = df.merge(df3, on=\"id\", how=\"left\")\n# df = df.merge(df4, on=\"id\", how=\"left\")\n\ndf_test = df_test.merge(df_test1, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test2, on=\"id\", how=\"left\")\n# df_test = df_test.merge(df_test3, on=\"id\", how=\"left\")\n# df_test = df_test.merge(df_test4, on=\"id\", how=\"left\")\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T19:53:28.300238Z","iopub.execute_input":"2021-08-30T19:53:28.300559Z","iopub.status.idle":"2021-08-30T19:53:30.429627Z","shell.execute_reply.started":"2021-08-30T19:53:28.300530Z","shell.execute_reply":"2021-08-30T19:53:30.428855Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"   id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8  ...     cont8     cont9  \\\n0   1    B    B    B    C    B    B    A    E    C  ...  0.389470  0.267559   \n1   2    B    B    A    A    B    D    A    F    A  ...  0.594928  0.341439   \n2   3    A    A    A    C    B    D    A    D    A  ...  0.555205  0.843531   \n3   4    B    B    A    C    B    D    A    E    C  ...  0.679618  0.574844   \n4   6    A    A    A    C    B    D    A    E    A  ...  0.684501  0.956692   \n\n     cont10    cont11    cont12    cont13    target  kfold    pred_1    pred_2  \n0  0.237281  0.377873  0.322401  0.869850  8.113634      0  8.431372  8.123327  \n1  0.906013  0.921701  0.261975  0.465083  8.481233      2  8.452841       NaN  \n2  0.748809  0.620126  0.541474  0.763846  8.364351      4  8.205483       NaN  \n3  0.346010  0.714610  0.540150  0.280682  8.049253      3  8.316980       NaN  \n4  1.000773  0.776742  0.625849  0.250823  7.972260      1  8.290789       NaN  \n\n[5 rows x 29 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cat0</th>\n      <th>cat1</th>\n      <th>cat2</th>\n      <th>cat3</th>\n      <th>cat4</th>\n      <th>cat5</th>\n      <th>cat6</th>\n      <th>cat7</th>\n      <th>cat8</th>\n      <th>...</th>\n      <th>cont8</th>\n      <th>cont9</th>\n      <th>cont10</th>\n      <th>cont11</th>\n      <th>cont12</th>\n      <th>cont13</th>\n      <th>target</th>\n      <th>kfold</th>\n      <th>pred_1</th>\n      <th>pred_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B</td>\n      <td>B</td>\n      <td>B</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>...</td>\n      <td>0.389470</td>\n      <td>0.267559</td>\n      <td>0.237281</td>\n      <td>0.377873</td>\n      <td>0.322401</td>\n      <td>0.869850</td>\n      <td>8.113634</td>\n      <td>0</td>\n      <td>8.431372</td>\n      <td>8.123327</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>F</td>\n      <td>A</td>\n      <td>...</td>\n      <td>0.594928</td>\n      <td>0.341439</td>\n      <td>0.906013</td>\n      <td>0.921701</td>\n      <td>0.261975</td>\n      <td>0.465083</td>\n      <td>8.481233</td>\n      <td>2</td>\n      <td>8.452841</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>D</td>\n      <td>A</td>\n      <td>...</td>\n      <td>0.555205</td>\n      <td>0.843531</td>\n      <td>0.748809</td>\n      <td>0.620126</td>\n      <td>0.541474</td>\n      <td>0.763846</td>\n      <td>8.364351</td>\n      <td>4</td>\n      <td>8.205483</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>...</td>\n      <td>0.679618</td>\n      <td>0.574844</td>\n      <td>0.346010</td>\n      <td>0.714610</td>\n      <td>0.540150</td>\n      <td>0.280682</td>\n      <td>8.049253</td>\n      <td>3</td>\n      <td>8.316980</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>A</td>\n      <td>...</td>\n      <td>0.684501</td>\n      <td>0.956692</td>\n      <td>1.000773</td>\n      <td>0.776742</td>\n      <td>0.625849</td>\n      <td>0.250823</td>\n      <td>7.972260</td>\n      <td>1</td>\n      <td>8.290789</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows  29 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"useful_features = [\"pred_1\", \"pred_2\"]\ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\ndef optimize_blending(trial):\n    \n    for fold in range(5):\n        learning_rate = trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True)\n        reg_lambda = trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0)\n        reg_alpha = trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0)\n        subsample = trial.suggest_float(\"subsample\", 0.1, 1.0)\n        colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n        max_depth = trial.suggest_int(\"max_depth\", 1, 7)\n\n        xtrain =  df[df.kfold != fold].reset_index(drop=True)\n        xvalid = df[df.kfold == fold].reset_index(drop=True)\n        xtest = df_test.copy()\n\n        ytrain = xtrain.target\n        yvalid = xvalid.target\n\n        xtrain = xtrain[useful_features]\n        xvalid = xvalid[useful_features]\n        \n        model = XGBRegressor(\n        random_state=fold,\n        learning_rate=learning_rate,\n        reg_lambda=reg_lambda,\n        reg_alpha=reg_alpha,\n        subsample=subsample,\n        colsample_bytree=colsample_bytree,\n        max_depth=max_depth,\n        n_estimators=7000,tree_method='gpu_hist',\n        gpu_id=0,\n        predictor=\"gpu_predictor\",\n            \n    )\n        model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n        preds_valid = model.predict(xvalid)\n        rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n        print(fold, rmse)\n        scores.append(rmse)\n        return rmse\n#print(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-30T19:53:35.554668Z","iopub.execute_input":"2021-08-30T19:53:35.554999Z","iopub.status.idle":"2021-08-30T19:53:35.582262Z","shell.execute_reply.started":"2021-08-30T19:53:35.554969Z","shell.execute_reply":"2021-08-30T19:53:35.581432Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction=\"minimize\")\nstudy.optimize(optimize_blending, n_trials=15)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T19:53:46.112601Z","iopub.execute_input":"2021-08-30T19:53:46.112959Z","iopub.status.idle":"2021-08-30T19:54:09.510291Z","shell.execute_reply.started":"2021-08-30T19:53:46.112928Z","shell.execute_reply":"2021-08-30T19:54:09.509506Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2021-08-30 19:53:46,114]\u001b[0m A new study created in memory with name: no-name-25b4c95f-a0e3-4481-a920-97329f7e2a1d\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-rmse:7.63215\n[840]\tvalidation_0-rmse:0.71607\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2021-08-30 19:53:47,968]\u001b[0m Trial 0 finished with value: 0.7160591650271125 and parameters: {'learning_rate': 0.019166258780540017, 'reg_lambda': 22.784776028696673, 'reg_alpha': 0.8717395894027744, 'subsample': 0.7932580575546805, 'colsample_bytree': 0.5530513712998397, 'max_depth': 3}. Best is trial 0 with value: 0.7160591650271125.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"0 0.7160591650271125\n[0]\tvalidation_0-rmse:7.69510\n[1000]\tvalidation_0-rmse:0.71604\n[1389]\tvalidation_0-rmse:0.71605\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2021-08-30 19:53:49,643]\u001b[0m Trial 1 finished with value: 0.7160343450482172 and parameters: {'learning_rate': 0.010999850553622608, 'reg_lambda': 15.638311879225217, 'reg_alpha': 0.0079352273475891, 'subsample': 0.3126700722837664, 'colsample_bytree': 0.8066622591449545, 'max_depth': 2}. Best is trial 1 with value: 0.7160343450482172.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"0 0.7160343450482172\n[0]\tvalidation_0-rmse:6.26168\n[364]\tvalidation_0-rmse:0.71642\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2021-08-30 19:53:50,544]\u001b[0m Trial 2 finished with value: 0.716167169419351 and parameters: {'learning_rate': 0.19729871650760875, 'reg_lambda': 27.372392345636978, 'reg_alpha': 4.4456151044560363e-07, 'subsample': 0.3182248539647216, 'colsample_bytree': 0.20286759992169767, 'max_depth': 6}. Best is trial 1 with value: 0.7160343450482172.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"0 0.716167169419351\n[0]\tvalidation_0-rmse:7.43122\n[498]\tvalidation_0-rmse:0.71631\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2021-08-30 19:53:52,425]\u001b[0m Trial 3 finished with value: 0.7162066131852972 and parameters: {'learning_rate': 0.04524476456668035, 'reg_lambda': 7.734231152213524, 'reg_alpha': 0.0028983776824857703, 'subsample': 0.662002820403254, 'colsample_bytree': 0.5528299972799496, 'max_depth': 7}. Best is trial 1 with value: 0.7160343450482172.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"0 0.7162066131852972\n[0]\tvalidation_0-rmse:7.48215\n[538]\tvalidation_0-rmse:0.71616\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2021-08-30 19:53:53,371]\u001b[0m Trial 4 finished with value: 0.7160924566867437 and parameters: {'learning_rate': 0.038615773754976074, 'reg_lambda': 1.4408202948284945e-06, 'reg_alpha': 0.3120222444095932, 'subsample': 0.765569539443997, 'colsample_bytree': 0.785962460046084, 'max_depth': 4}. Best is trial 1 with value: 0.7160343450482172.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"0 0.7160924566867437\n[0]\tvalidation_0-rmse:7.31607\n[441]\tvalidation_0-rmse:0.71618\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2021-08-30 19:53:54,157]\u001b[0m Trial 5 finished with value: 0.7161040642308326 and parameters: {'learning_rate': 0.06017602354621338, 'reg_lambda': 9.394905842498815e-06, 'reg_alpha': 1.3890478944497628e-07, 'subsample': 0.6767171650639213, 'colsample_bytree': 0.33144738110033367, 'max_depth': 4}. Best is trial 1 with value: 0.7160343450482172.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"0 0.7161040642308326\n[0]\tvalidation_0-rmse:6.82354\n[1000]\tvalidation_0-rmse:0.71613\n[1319]\tvalidation_0-rmse:0.71613\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2021-08-30 19:53:55,743]\u001b[0m Trial 6 finished with value: 0.7161203150478576 and parameters: {'learning_rate': 0.12419114841165702, 'reg_lambda': 1.2983443140877307, 'reg_alpha': 75.56892023536537, 'subsample': 0.4269025293544081, 'colsample_bytree': 0.3665002411893955, 'max_depth': 1}. Best is trial 1 with value: 0.7160343450482172.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"0 0.7161203150478576\n[0]\tvalidation_0-rmse:7.66211\n[852]\tvalidation_0-rmse:0.71624\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2021-08-30 19:53:58,097]\u001b[0m Trial 7 finished with value: 0.7162038259371549 and parameters: {'learning_rate': 0.015267614981624942, 'reg_lambda': 1.1313296608687397e-06, 'reg_alpha': 0.01427002701166256, 'subsample': 0.27406020836176537, 'colsample_bytree': 0.8689054919408253, 'max_depth': 6}. Best is trial 1 with value: 0.7160343450482172.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"0 0.7162038259371549\n[0]\tvalidation_0-rmse:7.25316\n[433]\tvalidation_0-rmse:0.71618\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2021-08-30 19:53:58,893]\u001b[0m Trial 8 finished with value: 0.7160879053212202 and parameters: {'learning_rate': 0.06833341304337696, 'reg_lambda': 0.3163352872095286, 'reg_alpha': 1.0436863289846183e-05, 'subsample': 0.823998912720003, 'colsample_bytree': 0.8877662489446271, 'max_depth': 4}. Best is trial 1 with value: 0.7160343450482172.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"0 0.7160879053212202\n[0]\tvalidation_0-rmse:5.85759\n[331]\tvalidation_0-rmse:0.71654\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2021-08-30 19:53:59,407]\u001b[0m Trial 9 finished with value: 0.7160689013319208 and parameters: {'learning_rate': 0.24972945181361336, 'reg_lambda': 7.841954180535813e-06, 'reg_alpha': 0.00023532744290084227, 'subsample': 0.14769351519215373, 'colsample_bytree': 0.7375766501516121, 'max_depth': 3}. Best is trial 1 with value: 0.7160343450482172.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"0 0.7160689013319208\n[0]\tvalidation_0-rmse:7.69954\n[1000]\tvalidation_0-rmse:0.71660\n[2000]\tvalidation_0-rmse:0.71619\n[3000]\tvalidation_0-rmse:0.71615\n[4000]\tvalidation_0-rmse:0.71613\n[4506]\tvalidation_0-rmse:0.71613\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2021-08-30 19:54:04,056]\u001b[0m Trial 10 finished with value: 0.7161324885412395 and parameters: {'learning_rate': 0.01042383589159202, 'reg_lambda': 0.007884641414042314, 'reg_alpha': 34.545202066889665, 'subsample': 0.12837300282853242, 'colsample_bytree': 0.6717516554028448, 'max_depth': 1}. Best is trial 1 with value: 0.7160343450482172.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"0 0.7161324885412395\n[0]\tvalidation_0-rmse:7.62357\n[993]\tvalidation_0-rmse:0.71607\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2021-08-30 19:54:05,293]\u001b[0m Trial 11 finished with value: 0.7160613907853649 and parameters: {'learning_rate': 0.020269026666155494, 'reg_lambda': 0.014586149680824636, 'reg_alpha': 0.6217028532340929, 'subsample': 0.9584336551474979, 'colsample_bytree': 0.5412789795558409, 'max_depth': 2}. Best is trial 1 with value: 0.7160343450482172.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"0 0.7160613907853649\n[0]\tvalidation_0-rmse:7.60127\n[1000]\tvalidation_0-rmse:0.71606\n[1020]\tvalidation_0-rmse:0.71605\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2021-08-30 19:54:06,670]\u001b[0m Trial 12 finished with value: 0.7160431665676945 and parameters: {'learning_rate': 0.023192650969160875, 'reg_lambda': 50.70802376653459, 'reg_alpha': 1.028711419792025, 'subsample': 0.5053060482267447, 'colsample_bytree': 0.5677608106672491, 'max_depth': 2}. Best is trial 1 with value: 0.7160343450482172.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"0 0.7160431665676945\n[0]\tvalidation_0-rmse:7.69707\n[1000]\tvalidation_0-rmse:0.71606\n[1415]\tvalidation_0-rmse:0.71605\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2021-08-30 19:54:08,384]\u001b[0m Trial 13 finished with value: 0.7160534143573599 and parameters: {'learning_rate': 0.010752572983615948, 'reg_lambda': 62.823764956423275, 'reg_alpha': 0.026103427697755352, 'subsample': 0.5017561160607915, 'colsample_bytree': 0.6452851348843129, 'max_depth': 2}. Best is trial 1 with value: 0.7160343450482172.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"0 0.7160534143573599\n[0]\tvalidation_0-rmse:7.56890\n[901]\tvalidation_0-rmse:0.71606\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2021-08-30 19:54:09,505]\u001b[0m Trial 14 finished with value: 0.7160348327005465 and parameters: {'learning_rate': 0.027363737776892067, 'reg_lambda': 1.646766250459745e-08, 'reg_alpha': 0.0002005968608931572, 'subsample': 0.3641608513914987, 'colsample_bytree': 0.9752119542583748, 'max_depth': 2}. Best is trial 1 with value: 0.7160343450482172.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"0 0.7160348327005465\n","output_type":"stream"}]},{"cell_type":"code","source":"study.best_params","metadata":{"execution":{"iopub.status.busy":"2021-08-30T19:54:53.714805Z","iopub.execute_input":"2021-08-30T19:54:53.715156Z","iopub.status.idle":"2021-08-30T19:54:53.722078Z","shell.execute_reply.started":"2021-08-30T19:54:53.715125Z","shell.execute_reply":"2021-08-30T19:54:53.721103Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"{'learning_rate': 0.010999850553622608,\n 'reg_lambda': 15.638311879225217,\n 'reg_alpha': 0.0079352273475891,\n 'subsample': 0.3126700722837664,\n 'colsample_bytree': 0.8066622591449545,\n 'max_depth': 2}"},"metadata":{}}]},{"cell_type":"code","source":"blend_parms={'learning_rate': 0.010999850553622608,\n 'reg_lambda': 15.638311879225217,\n 'reg_alpha': 0.0079352273475891,\n 'subsample': 0.3126700722837664,\n 'colsample_bytree': 0.8066622591449545,\n 'max_depth': 2}\nxgb_blend_params={'n_estimators': 7000,\n                **blend_parms,\n                'random_state': 0\n               }\n\nfinal_test_predictions = []\n#final_valid_predictions = {}\nscores = []\nfor fold in range(5):\n\n        xtrain =  df[df.kfold != fold].reset_index(drop=True)\n        xvalid = df[df.kfold == fold].reset_index(drop=True)\n        xtest = df_test.copy()\n\n        ytrain = xtrain.target\n        yvalid = xvalid.target\n\n        xtrain = xtrain[useful_features]\n        xvalid = xvalid[useful_features]\n        \n        model = XGBRegressor(**xgb_blend_params)\n        model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n        preds_valid = model.predict(xvalid)\n        test_preds = model.predict(xtest)\n        final_predictions.append(test_preds)\n        rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n        print(fold, rmse)\n        scores.append(rmse)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-30T19:55:30.996944Z","iopub.execute_input":"2021-08-30T19:55:30.997258Z","iopub.status.idle":"2021-08-30T19:59:03.259724Z","shell.execute_reply.started":"2021-08-30T19:55:30.997228Z","shell.execute_reply":"2021-08-30T19:59:03.258893Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"[0]\tvalidation_0-rmse:7.69508\n[1000]\tvalidation_0-rmse:0.71605\n[1537]\tvalidation_0-rmse:0.71606\n0 0.7160476905210753\n[0]\tvalidation_0-rmse:7.69182\n[1000]\tvalidation_0-rmse:0.71588\n[1238]\tvalidation_0-rmse:0.71588\n1 0.7158813670125022\n[0]\tvalidation_0-rmse:7.68956\n[1000]\tvalidation_0-rmse:0.71791\n[1024]\tvalidation_0-rmse:0.71791\n2 0.7178996950648469\n[0]\tvalidation_0-rmse:7.69187\n[1000]\tvalidation_0-rmse:0.71771\n[1194]\tvalidation_0-rmse:0.71771\n3 0.7177046943248524\n[0]\tvalidation_0-rmse:7.69731\n[1000]\tvalidation_0-rmse:0.71594\n[1622]\tvalidation_0-rmse:0.71593\n4 0.7159209642589889\n","output_type":"stream"}]},{"cell_type":"code","source":"#preds=model.predict(X_test)\nsample_submission.target = np.mean(np.column_stack(final_predictions), axis=1)\nsample_submission.to_csv(\"submission_cpu_takur_optuna_blending_2models.csv\", index = False)\nprint(\"Sent\")\n","metadata":{"execution":{"iopub.status.busy":"2021-08-30T19:59:08.075129Z","iopub.execute_input":"2021-08-30T19:59:08.075448Z","iopub.status.idle":"2021-08-30T19:59:08.565106Z","shell.execute_reply.started":"2021-08-30T19:59:08.075417Z","shell.execute_reply":"2021-08-30T19:59:08.564145Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Sent\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}